{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression():\n",
    "    def __init__(self, BatchSize, LearningRate = 10**(-6), ErrorTolerance=10**(-5), Verbose = True):\n",
    "        self.LearningRate = LearningRate\n",
    "        self.ErrorTolerance = ErrorTolerance\n",
    "        self.Verbose = Verbose\n",
    "        self.BatchSize = BatchSize\n",
    "        \n",
    "    def __posterior(self, theta_hat_0, theta_hat, x):\n",
    "        x = np.array(x)\n",
    "        return np.array(1/(1+np.exp(-(theta_hat_0 + np.matmul(theta_hat, x.T)))))\n",
    "\n",
    "    def __log_loss_func(self, theta_hat_0, theta_hat, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        p = self.__posterior(theta_hat_0,theta_hat,x)\n",
    "\n",
    "        log_p = np.array(pd.Series(np.log(p)).replace(to_replace=[np.inf,np.NINF],value=[0,0]))\n",
    "        log_p_ = np.array(pd.Series(np.log(1-p)).replace(to_replace=[np.inf,np.NINF],value=[0,0]))\n",
    "\n",
    "        lhs = np.matmul(y,log_p)\n",
    "        rhs = np.matmul((1-y),log_p_)\n",
    "\n",
    "        return -(lhs + rhs)\n",
    "    \n",
    "    def __derivative_theta_hat_0(self, theta_hat_0, theta_hat, x, y):\n",
    "#         o_0 represents theta hat zero\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        o_0 = ((y-1) * np.exp(theta_hat_0+np.matmul(theta_hat, x.T)) + y) / (np.exp(theta_hat_0+np.matmul(theta_hat, x.T)) + 1)\n",
    "\n",
    "        o_0 = np.array(pd.Series(o_0).replace(to_replace=[np.nan],value=[0]))\n",
    "\n",
    "        return np.sum(o_0)\n",
    "    \n",
    "    def __derivative_theta_hat(self, theta_hat_0, theta_hat, x, y):\n",
    "#         o represents theta hat\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        o = ((y-1) * np.exp(theta_hat_0+np.matmul(theta_hat, x.T)) + y) / (np.exp(theta_hat_0+np.matmul(theta_hat, x.T)) + 1)\n",
    "\n",
    "        o = np.array(pd.Series(o).replace(to_replace=[np.nan],value=[0]))\n",
    "\n",
    "        o = np.matmul(x.T, o)\n",
    "\n",
    "        return o\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        epoch_counter = 1\n",
    "        \n",
    "        X = np.array(X_train)\n",
    "        Y = np.array(Y_train)\n",
    "        \n",
    "        theta_hat_0_initial = 1\n",
    "        theta_hat_initial = np.array([1 for _ in range(X.shape[1])])\n",
    "                                                       \n",
    "        while True:\n",
    "            for i in range(X.shape[0]//self.BatchSize):\n",
    "                \n",
    "                random_indices = np.random.choice(a=np.arange(0,X.shape[0]),size=self.BatchSize,replace=False)\n",
    "                X_batch = X[random_indices]\n",
    "                Y_batch = Y[random_indices]\n",
    "                                                       \n",
    "                self.theta_hat_0_final = theta_hat_0_initial-(self.LearningRate*self.__derivative_theta_hat_0(theta_hat_0_initial\n",
    "                                                                                              ,theta_hat_initial,X_batch,Y_batch))\n",
    "\n",
    "                self.theta_hat_final = theta_hat_initial-(self.LearningRate*self.__derivative_theta_hat(theta_hat_0_initial\n",
    "                                                                                        ,theta_hat_initial,X_batch,Y_batch))\n",
    "\n",
    "                log_loss_func_initial = self.__log_loss_func(theta_hat_0_initial,theta_hat_initial,X_batch,Y_batch)\n",
    "                log_loss_func_final = self.__log_loss_func(self.theta_hat_0_final,self.theta_hat_final,X_batch,Y_batch)\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                theta_hat_0_initial = self.theta_hat_0_final\n",
    "                theta_hat_initial = self.theta_hat_final\n",
    "            \n",
    "            if abs(log_loss_func_initial - log_loss_func_final) < self.ErrorTolerance:\n",
    "                if self.Verbose:\n",
    "                    print(f'\\nConvergence has Acheived. Epoch = {epoch_counter}, Value of Log Loss Function = {log_loss_func_final}.\\n')\n",
    "                break\n",
    "            \n",
    "            if self.Verbose:\n",
    "                print(f'Epoch = {epoch_counter}, Value of Log Loss Function = {log_loss_func_final}.\\n\\n')\n",
    "            \n",
    "            epoch_counter += 1\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        self.predicted_labels = np.array(pd.Series(self.__posterior(self.theta_hat_0_final,self.theta_hat_final,X_test) > 0.5).replace(to_replace=[True, False], value=[1,0]))\n",
    "        return self.predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit16fa44404e4941f7996ce5d53eb37087"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
