{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this we will convert categorical data into continuous data, which will definetly improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Binary_Logistic_Regression import BinaryLogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mushrooms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df):\n",
    "    data_array = list()\n",
    "    column_name = list()\n",
    "    for column in df.columns:\n",
    "        unique = df[column].unique()\n",
    "        size = len(df[column].unique())\n",
    "        df[column].replace(to_replace=unique, value=range(size), inplace=True)\n",
    "        data_array.append(np.eye(size, size)[df[column]])\n",
    "        for u in unique:\n",
    "            column_name.append(column + '_' + str(u))\n",
    "    return pd.DataFrame(np.concatenate(data_array, axis=1), columns=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = one_hot_encoding(data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = (new_data - new_data.mean(axis=0))/new_data.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].replace(to_replace=['p', 'e'],value=[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLR_Mushroom(BinaryLogisticRegression):\n",
    "    def __init__(self, X, Y, n_comp, LR=10**(-6), ET=10**(-5)):\n",
    "        \n",
    "        pca = PCA(n_components=n_comp)\n",
    "        self.data_after_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        \n",
    "        self.data_after_pca['class'] = Y\n",
    "        \n",
    "        p = self.data_after_pca[self.data_after_pca['class'] == 1]\n",
    "        e = self.data_after_pca[self.data_after_pca['class'] == 0]\n",
    "        \n",
    "        self.train = pd.concat([p.iloc[:int(X.shape[0] * 0.7)//2,:], e.iloc[:int(X.shape[0] * 0.7)//2,:]], axis=0)\n",
    "        \n",
    "        remaining = pd.concat([p.iloc[int(X.shape[0] * 0.7)//2:,:], e.iloc[int(X.shape[0] * 0.7)//2:,:]])\n",
    "        \n",
    "        X_cv, X_test, Y_cv, Y_test = train_test_split(remaining.iloc[:,:-1],remaining['class'],test_size=1/2)\n",
    "        \n",
    "        self.cv = pd.DataFrame(X_cv)\n",
    "        self.cv['class'] = Y_cv\n",
    "        \n",
    "        self.test = pd.DataFrame(X_test)\n",
    "        self.test['class'] = Y_test\n",
    "        \n",
    "        del pca, p, e, remaining, X_cv, X_test, Y_cv, Y_test\n",
    "        \n",
    "        super().__init__(1, LearningRate=LR, ErrorTolerance=ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predicted, actual):\n",
    "    TP = np.count_nonzero((predicted == 1) & (actual == 1))\n",
    "    TN = np.count_nonzero((predicted == 0) & (actual == 0))\n",
    "    FP = np.count_nonzero((predicted == 1) & (actual == 0))\n",
    "    FN = np.count_nonzero((predicted == 0) & (actual == 1))\n",
    "    \n",
    "    \n",
    "    if (TP + TN + FP + FN) == 0:\n",
    "        accuracy = 0\n",
    "    else:\n",
    "        accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "    \n",
    "    if (TP + FP) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "    \n",
    "    if (TP + FN) == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TP/(TP + FN)\n",
    "        \n",
    "    if (precision + recall) == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = (2 * precision * recall)/(precision + recall)\n",
    "    \n",
    "    return (accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = dict()\n",
    "best = {'Accuracy':0, 'Precision':0, 'Recall':0, 'F1 Score':0, 'Best Obj':'obj', 'Parameter':()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Different Combinaitions of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_comp in range(2,36):\n",
    "    for LR in [5,6,7,8,9,10]:\n",
    "        for ET in [5,6,7,8,9,10]:\n",
    "            obj = BinaryLR_Mushroom(new_data, data['class'], n_comp, LR=10**(-LR), ET=10**(-ET))\n",
    "            obj.fit(obj.train.iloc[:,:-1], obj.train['class'])\n",
    "            print('---------------------------------------------------------------------------')\n",
    "            obj.predict(obj.cv.iloc[:,:-1])\n",
    "            Results[(n_comp, LR, ET)] = evaluate(obj.predicted_labels, obj.cv['class'])\n",
    "            if (Results[(n_comp, LR, ET)][0] + Results[(n_comp, LR, ET)][1] + Results[(n_comp, LR, ET)][2]) > (best['Accuracy'] + best['Precision'] + best['Recall']):\n",
    "                best['Accuracy'] = Results[(n_comp, LR, ET)][0]\n",
    "                best['Precision'] = Results[(n_comp, LR, ET)][1]\n",
    "                best['Recall'] = Results[(n_comp, LR, ET)][2]\n",
    "                best['F1 Score'] = Results[(n_comp, LR, ET)][3]\n",
    "                best['Best Obj'] = obj\n",
    "                best['Parameter'] = (n_comp, LR, ET)\n",
    "            else:\n",
    "                del obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From over 1260 Hyperparameter combinaitons we find our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_obj = best['Best Obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_obj.predict(best_obj.test_data.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(best_obj.predicted_labels, best_obj.test_data['class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit16fa44404e4941f7996ce5d53eb37087"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
