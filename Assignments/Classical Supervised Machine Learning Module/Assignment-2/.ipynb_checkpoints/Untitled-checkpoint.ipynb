{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gausian_NB():\n",
    "    \n",
    "    def __init__(self,features,labels,data_split_ratio,Apply_PCA,n_components):\n",
    "        self.X = features\n",
    "        self.Y = np.array(labels).reshape(labels.shape[0],1) \n",
    "        self.ratio = data_split_ratio\n",
    "        self.n_components = n_components\n",
    "        if Apply_PCA == True:\n",
    "            self.X = self.pca(self.X, self.n_components)\n",
    "            \n",
    "            \n",
    "    def pca(self,data, n_components):\n",
    "        X = np.array(data)\n",
    "        X_dash = X - X.mean(axis=0)\n",
    "        cov = (1/X.shape[0]) * np.matmul(X_dash.T, X_dash)\n",
    "        Q = np.linalg.svd(cov)[0]\n",
    "        Q_tilda = Q[:,:n_components]\n",
    "        X_new = np.matmul(X_dash, Q_tilda)\n",
    "        data_new = pd.DataFrame(X_new)\n",
    "        return data_new\n",
    "    \n",
    "    \n",
    "    def split_data(self):\n",
    "        data = pd.DataFrame(self.X)\n",
    "        data['diagnosis'] = self.Y\n",
    "        Data_pos = data[data['diagnosis'] == np.unique(self.Y)[0]]\n",
    "        Data_neg = data[data['diagnosis'] == np.unique(self.Y)[1]]\n",
    "        \n",
    "        Training_data_count = int(data.shape[0]*self.ratio[0])\n",
    "        CV_data_count = int(data.shape[0]*self.ratio[1])\n",
    "        Test_data_count = data.shape[0] - (Training_data_count + CV_data_count)\n",
    "        \n",
    "        Training_data = pd.concat([Data_pos.iloc[:Training_data_count//2,:], Data_neg.iloc[:Training_data_count//2,:]])\n",
    "        \n",
    "        Remaing_data = pd.concat([Data_pos.iloc[Training_data_count//2:,:],Data_neg.iloc[Training_data_count//2:,:]])\n",
    "        \n",
    "        Random_number = np.random.choice(np.arange(0,171), size=171, replace=False)\n",
    "        Remaing_data = Remaing_data.iloc[Random_number]\n",
    "        \n",
    "        CV_data = Remaing_data.iloc[:CV_data_count,:]\n",
    "        \n",
    "        Testing_data = Remaing_data.iloc[CV_data_count:,:]\n",
    "        \n",
    "        return Training_data, CV_data, Testing_data\n",
    "    \n",
    "    \n",
    "    def fit(self,data):\n",
    "        training_data_pos = data[data['diagnosis'] == np.unique(self.Y)[0]].iloc[:,:-1]\n",
    "        training_data_neg = data[data['diagnosis'] == np.unique(self.Y)[0]].iloc[:,:-1]\n",
    "        self.mean = np.array([training_data_pos.mean(axis=0), training_data_neg.mean(axis=0)])\n",
    "        self.cov = np.array([training_data_pos.cov(), training_data_neg.cov()])\n",
    "        self.prior = np.array([training_data_pos.shape[0]/data.shape[0], training_data_neg.shape[0]/data.shape[0]])\n",
    "#         print('Mean :- ', self.mean, '\\nCOV :- ', self.cov, '\\nPrior :- ', self.prior)\n",
    "\n",
    "        \n",
    "    def evaluate(self, data):\n",
    "        posterior_m = np.array(s.multivariate_normal.pdf(data.iloc[:,:-1], self.mean[0], self.cov[0]) * self.prior[0])\n",
    "        posterior_b = np.array(s.multivariate_normal.pdf(data.iloc[:,:-1], self.mean[1], self.cov[1]) * self.prior[1])\n",
    "#         print(posterior_m, posterior_b)\n",
    "        Boolean_mask = pd.Series(posterior_b > posterior_m)\n",
    "        predicted = np.array(Boolean_mask.replace(to_replace=[True, False], value=['B', 'M']))\n",
    "        self.performance(predicted, data.iloc[:,-1])\n",
    "        print('\\nPredicted = ', predicted, '\\n\\nActual =',np.array(data.iloc[:,-1]))\n",
    "    \n",
    "        \n",
    "    def performance(self, actual,predicted,):\n",
    "\n",
    "        TP = np.count_nonzero((predicted == 'M') & (actual == 'M'))\n",
    "        TN = np.count_nonzero((predicted == 'B') & (actual == 'B'))\n",
    "        FP = np.count_nonzero((predicted == 'M') & (actual == 'B'))\n",
    "        FN = np.count_nonzero((predicted == 'B') & (actual == 'M'))\n",
    "\n",
    "        if (TP+TN+FP+FN) == 0:\n",
    "            Accuracy = 0\n",
    "        else:\n",
    "            Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "        if (TP+FP) == 0:\n",
    "            Precision = 0\n",
    "        else:\n",
    "            Precision = TP/(TP+FP)\n",
    "\n",
    "        if (TP+FN) == 0:\n",
    "            Recall = 0\n",
    "        else:\n",
    "            Recall = TP/(TP+FN)\n",
    "\n",
    "        if (Precision+Recall) == 0:\n",
    "            F1_Score = 0\n",
    "        else:\n",
    "            F1_Score = (2*Precision*Recall)/(Precision+Recall)\n",
    "\n",
    "        print(f' Accuracy = {Accuracy} \\n Precision = {Precision} \\n Recall = {Recall} \\n F1-Score = {F1_Score}')\n",
    "\n",
    "        return {'Accuracy':Accuracy, 'Precision':Precision, 'Recall':Recall, 'F1-Score':F1_Score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([data.columns[0], data.columns[-1]], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Gausian_NB(data.iloc[:,1:], data.iloc[:,0], (0.7, 0.2, 0.1), True, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, CV, Test = clf.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.fit(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy = 0.061946902654867256 \n",
      " Precision = 1.0 \n",
      " Recall = 0.061946902654867256 \n",
      " F1-Score = 0.11666666666666665\n",
      "\n",
      "Predicted =  ['M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'M' 'M' 'M' 'M'] \n",
      "\n",
      "Actual = ['B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B']\n"
     ]
    }
   ],
   "source": [
    "clf.evaluate(CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit16fa44404e4941f7996ce5d53eb37087"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
